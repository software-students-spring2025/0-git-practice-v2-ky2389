# Git Practice
## Article Reference
- **Title:** [Understanding the Hidden Influences in LLM Distillation](https://arxiv.org/abs/2501.12619)  
## Commentary 
Ever since its release, the quality and originality of DeepSeek has been questioned by many. Recently, I found that when answering, sometimes DeepSeek would demonstrate ChatGPT-like properties, such as mentioning obedience to OpenAI policies. This undoubtedly raises concerns about its true internal nature.
However, the article by Lee et al. suggests that many models on the market rely on distilled model data, which might explain this behavior in DeepSeek. It could be simply a manifestation of this industry-wide practice rather than a direct replication of OpenAIâ€™s models.

###Comment
- Yuquan ----------
- Like it pretty much.

### Comment - Alan Chen
Hi Henry, thanks for sharing this interesting article. The article proposes a very robust way to evaluate the degree of distillation of LLMs. As you mention in the commentary, the use of distillation for model training has become an industry practice, especially after the bloom of open source model, it also raises debt of the legitimacy of using such method. On one hand, it is unfair for the frontier company who spend much more resources; On the other hand, doing so could benefit AI development in the larger picture since less computation will be needed on repetitive work. 